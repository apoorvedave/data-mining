{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)\n",
    "\n",
    "items = []\n",
    "users = []\n",
    "ratings = []\n",
    "nHelpFuls = []\n",
    "outOfs = []\n",
    "texts = []\n",
    "times = []\n",
    "counter = 0\n",
    "testindex = 0\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    items.append(l['itemID'])\n",
    "    users.append(l['reviewerID'])\n",
    "    ratings.append(l['rating'])\n",
    "    nHelpFuls.append(l['helpful']['nHelpful'])\n",
    "    outOfs.append(l['helpful']['outOf'])\n",
    "    texts.append(l['reviewText'])\n",
    "    times.append(l['unixReviewTime'])\n",
    "    counter += 1\n",
    "    if counter == 900000:\n",
    "        testindex = len(ratings)\n",
    "\n",
    "os.system('say \"Data Loaded\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemsdict = {}\n",
    "itemsavg = {}\n",
    "usersdict = {}\n",
    "usersavghelpful = {}\n",
    "userrevcount = defaultdict(int)\n",
    "\n",
    "for i in xrange(len(ratings)):\n",
    "    if items[i] not in itemsdict:\n",
    "        itemsdict[items[i]] = []\n",
    "    if times[i] not in itemsdict[items[i]]:\n",
    "        itemsdict[items[i]].append(times[i])\n",
    "\n",
    "for i in xrange(len(ratings)):\n",
    "    if items[i] not in itemsavg:\n",
    "        itemsavg[items[i]] = []\n",
    "    itemsavg[items[i]].append(ratings[i])\n",
    "    \n",
    "for i in xrange(len(ratings)):\n",
    "    if users[i] not in usersdict:\n",
    "        usersdict[users[i]] = []\n",
    "    if times[i] not in usersdict[users[i]]:\n",
    "        usersdict[users[i]].append(times[i])\n",
    "        \n",
    "for i in xrange(len(ratings)):\n",
    "    if outOfs[i] != 0:\n",
    "        if users[i] not in usersavghelpful:\n",
    "            usersavghelpful[users[i]] = []\n",
    "        usersavghelpful[users[i]].append(nHelpFuls[i]/outOfs[i])\n",
    "\n",
    "for i in xrange(len(ratings)):\n",
    "    userrevcount[users[i]] += 1\n",
    "    \n",
    "#kaggle data loading...\n",
    "kitems = []\n",
    "kusers = []\n",
    "kratings = []\n",
    "koutOfs = []\n",
    "ktexts = []\n",
    "ktimes = []\n",
    "for l in readGz(\"helpful.json.gz\"):\n",
    "    kitems.append(l['itemID'])\n",
    "    kusers.append(l['reviewerID'])\n",
    "    kratings.append(l['rating'])\n",
    "    koutOfs.append(l['helpful']['outOf'])\n",
    "    ktexts.append(l['reviewText'])\n",
    "    ktimes.append(l['unixReviewTime'])\n",
    "\n",
    "for i in xrange(len(kratings)):\n",
    "    if kitems[i] not in itemsdict:\n",
    "        itemsdict[kitems[i]] = []\n",
    "    if ktimes[i] not in itemsdict[kitems[i]]:\n",
    "        itemsdict[kitems[i]].append(ktimes[i])\n",
    "\n",
    "for i in xrange(len(kratings)):\n",
    "    if kitems[i] not in itemsavg:\n",
    "        itemsavg[kitems[i]] = []\n",
    "    itemsavg[kitems[i]].append(kratings[i])\n",
    "\n",
    "for key in itemsdict:\n",
    "    itemsdict[key].sort()\n",
    "os.system('say \"Kaggle data loaded\"')\n",
    "\n",
    "for key in itemsavg:\n",
    "    itemsavg[key] = sum(itemsavg[key])/len(itemsavg[key])\n",
    "    \n",
    "for i in xrange(len(kratings)):\n",
    "    if kusers[i] not in usersdict:\n",
    "        usersdict[kusers[i]] = []\n",
    "    if ktimes[i] not in usersdict[kusers[i]]:\n",
    "        usersdict[kusers[i]].append(ktimes[i])\n",
    "\n",
    "for key in usersdict:\n",
    "    usersdict[key].sort()\n",
    "\n",
    "for key in usersavghelpful:\n",
    "    usersavghelpful[key] = sum(usersavghelpful[key])/len(usersavghelpful[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = []\n",
    "outoftrain = []\n",
    "target = []\n",
    "test = []\n",
    "outoftest = []\n",
    "targettest = []\n",
    "for i in xrange(len(ratings)):\n",
    "    if outOfs[i] != 0:\n",
    "        row = []\n",
    "        #ratings\n",
    "        row.append(ratings[i])\n",
    "        \n",
    "        #wc\n",
    "        wc = texts[i].split()\n",
    "        row.append(len(wc))\n",
    "        \n",
    "        row.append(times[i])\n",
    "        row.append(outOfs[i])\n",
    "        \n",
    "        #MoreFeatures\n",
    "        #sentences\n",
    "        sc = texts[i].split('. ')\n",
    "        #row.append(len(sc))\n",
    "        \n",
    "        #avg words\n",
    "        b = float(len(wc))/len(sc)\n",
    "        row.append(b)\n",
    "        #avg chars\n",
    "        c = [len(w) for w in wc]\n",
    "        c = 0 if len(c) == 0 else float(sum(c))/len(c)\n",
    "        #row.append(c)\n",
    "        #readability\n",
    "        d = 4.71*c + 0.5*b - 21.43\n",
    "        row.append(d)\n",
    "        \n",
    "        #timed rank\n",
    "        # scale and try -val to + val etc... try scale next\n",
    "        rank = (len(itemsdict[items[i]])+1)/2.0 - (itemsdict[items[i]].index(times[i])+1)\n",
    "        row.append(rank)\n",
    "        \n",
    "        #time difference\n",
    "        diff = times[i] - itemsdict[items[i]][0]\n",
    "        row.append(diff)\n",
    "        \n",
    "        #deviation\n",
    "        dev = abs(ratings[i] - itemsavg[items[i]])\n",
    "        row.append(dev)\n",
    "        row.append(dev**2)\n",
    "        \n",
    "        #user properties\n",
    "        #timed rank\n",
    "        #rank = (len(usersdict[users[i]])+1)/2.0 - (usersdict[users[i]].index(times[i])+1)\n",
    "        #row.append(rank)\n",
    "        \n",
    "        #avg user helpfulness\n",
    "        #row.append(usersavghelpful[users[i]])\n",
    "        \n",
    "        #user rev count\n",
    "        #row.append(userrevcount[users[i]])\n",
    "        \n",
    "        #user product helpfulness count\n",
    "        row.append(userrevcount[users[i]]*usersavghelpful[users[i]])\n",
    "        \n",
    "        #if i < testindex:\n",
    "        train.append(row)\n",
    "        target.append(nHelpFuls[i]/float(outOfs[i]))\n",
    "        outoftrain.append(outOfs[i])\n",
    "        #else:\n",
    "        #    test.append(row)\n",
    "        #    targettest.append(nHelpFuls[i]/float(outOfs[i]))\n",
    "        #    outoftest.append(outOfs[i])\n",
    "            \n",
    "rf = RandomForestRegressor(n_estimators=200, n_jobs=-1)\n",
    "rf.fit(train, target)\n",
    "os.system('say \"Data Trained\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainpredict = rf.predict(train)\n",
    "testpredict = rf.predict(test)\n",
    "\n",
    "errors = []\n",
    "for i in range(len(trainpredict)):\n",
    "    errors.append(abs(target[i] - trainpredict[i])*outoftrain[i])\n",
    "mae = float(sum(errors))/len(errors)\n",
    "print mae\n",
    "\n",
    "errors = []\n",
    "for i in range(len(testpredict)):\n",
    "    errors.append(abs(targettest[i] - testpredict[i])*outoftest[i])\n",
    "mae = float(sum(errors))/len(errors)\n",
    "print mae\n",
    "os.system('say \"Errors Updated\"')\n",
    "\n",
    "\"\"\"\n",
    "mae corrected\n",
    "0.453925027129\n",
    "1.15620196629\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "0.45537700253\n",
    "1.15210030907\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "0.449873481314\n",
    "1.14146121432\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "len-rank for rank\n",
    "0.454805464773\n",
    "1.12437800129\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "len/rank as rank, default estimators\n",
    "0.463616939687\n",
    "1.12498733316\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "len - rank, 100 estimators\n",
    "0.415570064647\n",
    "1.077622777\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "0.398592495018: no c, len-rank = rank\n",
    "1.05560638633\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "try with nhelpfuls instead of ratio\n",
    "0.41684491092\n",
    "1.08506242674\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "ratio, rank rearranged\n",
    "0.399153271742\n",
    "1.05442916258\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "ratio, rank scaled:bekar\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "time diff\n",
    "0.396901957506\n",
    "1.04032779202\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "deviation\n",
    "0.374313124583\n",
    "0.989569597072\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "all 1000000 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userItemPrediction = defaultdict(list)\n",
    "kaggletest = []\n",
    "\n",
    "for i in range(len(kratings)):\n",
    "    row = []\n",
    "    #ratings\n",
    "    row.append(kratings[i])\n",
    "\n",
    "    #wc\n",
    "    wc = ktexts[i].split()\n",
    "    row.append(len(wc))\n",
    "\n",
    "    row.append(ktimes[i])\n",
    "    row.append(koutOfs[i])\n",
    "\n",
    "    #MoreFeatures\n",
    "    #sentences\n",
    "    sc = ktexts[i].split('. ')\n",
    "    #row.append(len(sc))\n",
    "\n",
    "    #avg words\n",
    "    b = float(len(wc))/len(sc)\n",
    "    row.append(b)\n",
    "    #avg chars\n",
    "    c = [len(w) for w in wc]\n",
    "    c = 0 if len(c) == 0 else float(sum(c))/len(c)\n",
    "    #row.append(c)\n",
    "    #readability\n",
    "    d = 4.71*c + 0.5*b - 21.43\n",
    "    row.append(d)\n",
    "\n",
    "    #timed rank\n",
    "    rank = (len(itemsdict[kitems[i]])+1)/2.0 - (itemsdict[kitems[i]].index(ktimes[i])+1)\n",
    "    row.append(rank)\n",
    "    \n",
    "    #time difference\n",
    "    diff = ktimes[i] - itemsdict[kitems[i]][0]\n",
    "    row.append(diff)\n",
    "\n",
    "    #deviation\n",
    "    dev = abs(kratings[i] - itemsavg[kitems[i]])\n",
    "    row.append(dev)\n",
    "    row.append(dev**2)\n",
    "    \n",
    "    #user properties\n",
    "    #timed rank\n",
    "    #rank = (len(usersdict[kusers[i]])+1)/2.0 - (usersdict[kusers[i]].index(ktimes[i])+1)\n",
    "    #row.append(rank)\n",
    "\n",
    "    #avg user helpfulness\n",
    "    if kusers[i] in usersavghelpful:\n",
    "        row.append(usersavghelpful[kusers[i]])\n",
    "    else:\n",
    "        row.append(0.0)\n",
    "    \n",
    "    #user rev count\n",
    "    #row.append(userrevcount[kusers[i]])\n",
    "    \n",
    "    #user product helpfulness count\n",
    "    if kusers[i] in usersavghelpful:\n",
    "        row.append(userrevcount[kusers[i]]*usersavghelpful[kusers[i]])\n",
    "    else:\n",
    "        row.append(0.0)\n",
    "    \n",
    "    kaggletest.append(row)\n",
    "\n",
    "kagglepredict = rf.predict(kaggletest)\n",
    "for i in range(len(kusers)):\n",
    "    userItemPrediction[kusers[i]+'-'+kitems[i]+'-'+str(koutOfs[i])] = koutOfs[i]*kagglepredict[i]\n",
    "\n",
    "f_out = open('outputTry1.txt', 'w')\n",
    "f = open('pairs_Helpful.txt', 'r')\n",
    "f_out.write(f.readline())\n",
    "for l in f.readlines():\n",
    "    f_out.write(l.rstrip('\\n')+','+str(userItemPrediction[l.rstrip('\\n')])+'\\n')\n",
    "f_out.close()\n",
    "f.close()\n",
    "os.system('say \"Kaggle calculated\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 8.63333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training the model: Linear\n",
    "from scipy.optimize import minimize\n",
    "def mse (a, helpfulness, f1, f2, f3):\n",
    "    #helpfulness = nHelpful/outOf\n",
    "    squared_error = 0\n",
    "    for i in range(len(helpfulness)):\n",
    "        squared_error += (helpfulness[i] - a[0] - a[1]*f1[i] - a[2]*f2[i])**2\n",
    "    mse = squared_error/len(helpfulness)\n",
    "    return mse\n",
    "\n",
    "f1 = train[:,1]\n",
    "f2 = train[:,2]\n",
    "f3 = train[:,3]\n",
    "res = minimize(mse, [0]*(len(train[0])-1), args=(target, f1, f2, f3), method='L-BFGS-B')\n",
    "print res\n",
    "\n",
    "a = res.x\n",
    "errors = []\n",
    "for i in range(len(alpha_array_test)):\n",
    "    errors.append(abs(nHelpful_test[i] - (a[0] + a[1]*wordCount_test[i] + a[2]*ratings_test[i])*outOf_test[i]))\n",
    "mae = sum(errors)/len(errors)\n",
    "print mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#<Q4>\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)\n",
    "\n",
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "\n",
    "userItemPrediction = defaultdict(list)\n",
    "\n",
    "userIds = []\n",
    "itemIds = []\n",
    "outOfs = []\n",
    "wordCounts = []\n",
    "ratings = []\n",
    "\n",
    "for l in readGz(\"helpful.json.gz\"):\n",
    "    user,item,outOf,rating,wordCount = l['reviewerID'],l['itemID'],l['helpful']['outOf'],l['rating'],len(l['reviewText'].split())\n",
    "    outOfs.append(outOf)\n",
    "    userIds.append(user)\n",
    "    itemIds.append(item)\n",
    "    wordCounts.append(wordCount)\n",
    "    ratings.append(rating)\n",
    "\n",
    "a = res.x\n",
    "userItemPrediction = defaultdict(list)\n",
    "\n",
    "for i in range(len(userIds)):\n",
    "    userItemPrediction[userIds[i]+'-'+itemIds[i]+'-'+str(outOfs[i])] = outOfs[i]*(a[0]+a[1]*wordCounts[i]+a[2]*ratings[i])\n",
    "\n",
    "f_out = open('output.txt', 'w')\n",
    "f = open('pairs_Helpful.txt', 'r')\n",
    "f_out.write(f.readline())\n",
    "for l in f.readlines():\n",
    "    f_out.write(l.rstrip('\\n')+','+str(userItemPrediction[l.rstrip('\\n')])+'\\n')\n",
    "f_out.close()\n",
    "f.close()\n",
    "\n",
    "#Kaggle user name/Id: apoorvedave/458740 \n",
    "#</Q4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#<Q5>\n",
    "rating_alpha = sum(ratings_train)/len(ratings_train)\n",
    "#4.0894368581424221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<Q6>\n",
    "file_read_counter = 0\n",
    "users_train = []\n",
    "items_train = []\n",
    "ratings_train = []\n",
    "\n",
    "users_test = []\n",
    "items_test = []\n",
    "ratings_test = []\n",
    "\n",
    "user_item_ratings_train = {}\n",
    "item_user_ratings_train = {}\n",
    "user_item_ratings_test = {}\n",
    "count = 0\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    if file_read_counter < 100000:\n",
    "        users_train.append(l['reviewerID'])\n",
    "        items_train.append(l['itemID'])\n",
    "        ratings_train.append(l['rating'])\n",
    "    elif file_read_counter >= 900000:\n",
    "        users_test.append(l['reviewerID'])\n",
    "        items_test.append(l['itemID'])\n",
    "        ratings_test.append(l['rating'])\n",
    "            \n",
    "    file_read_counter += 1\n",
    "    if file_read_counter %10000 == 0:\n",
    "        print file_read_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(users_train)):\n",
    "    if users_train[i] not in user_item_ratings_train:\n",
    "        user_item_ratings_train[users_train[i]] = {}\n",
    "    user_item_ratings_train[users_train[i]][items_train[i]] = ratings_train[i]\n",
    "    if items_train[i] not in item_user_ratings_train:\n",
    "        item_user_ratings_train[items_train[i]] = {}\n",
    "    item_user_ratings_train[items_train[i]][users_train[i]] = ratings_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "set_users = set(users_train)\n",
    "set_items = set(items_train)\n",
    "\n",
    "list_users = list(set_users)\n",
    "list_items = list(set_items)\n",
    "lam = 1\n",
    "\n",
    "beta_u = defaultdict(float)\n",
    "beta_i = defaultdict(float)\n",
    "\n",
    "for i in range(len(set_users)):\n",
    "    beta_u[list_users[i]] = 0\n",
    "for i in range(len(set_items)):\n",
    "    beta_i[list_items[i]] = 0\n",
    "\n",
    "old_alpha = 10\n",
    "\n",
    "for i in range(len(set_users)):\n",
    "    beta_u[list_users[i]] = 0\n",
    "for i in range(len(set_items)):\n",
    "    beta_i[list_items[i]] = 0\n",
    "old_alpha = 10\n",
    "\n",
    "while abs(alpha - old_alpha) > 0.001:\n",
    "    old_alpha = alpha\n",
    "    alpha = 0\n",
    "    for i in range(len(ratings_train)):\n",
    "        alpha += ratings_train[i] - beta_u[users_train[i]] - beta_i[items_train[i]]\n",
    "    alpha = alpha/len(ratings_train)\n",
    "\n",
    "    for user in beta_u:\n",
    "        beta_u[user] = 0\n",
    "        for item in user_item_ratings_train[user]:\n",
    "            beta_u[user] += user_item_ratings_train[user][item] - alpha - beta_i[item]\n",
    "        beta_u[user] = beta_u[user]/(lam+len(user_item_ratings_train[user]))\n",
    "\n",
    "    for item in beta_i:\n",
    "        beta_i[item] = 0\n",
    "        for user in item_user_ratings_train[item]:\n",
    "            beta_i[item] += item_user_ratings_train[item][user] - alpha - beta_u[user]\n",
    "        beta_i[item] = beta_i[item]/(lam + len(item_user_ratings_train[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mse_converge(lam):\n",
    "    global alpha, beta_u, beta_i,users_train,items_train,ratings_train, user_item_ratings_train \n",
    "    alpha = 0\n",
    "    for i in range(len(set_users)):\n",
    "        beta_u[list_users[i]] = 0\n",
    "    for i in range(len(set_items)):\n",
    "        beta_i[list_items[i]] = 0\n",
    "    old_alpha = 10\n",
    "    \n",
    "    while abs(alpha - old_alpha) > 0.001:\n",
    "        old_alpha = alpha\n",
    "        alpha = 0\n",
    "        for i in range(len(ratings_train)):\n",
    "            alpha += ratings_train[i] - beta_u[users_train[i]] - beta_i[items_train[i]]\n",
    "        alpha = alpha/len(ratings_train)\n",
    "\n",
    "        for user in beta_u:\n",
    "            beta_u[user] = 0\n",
    "            for item in user_item_ratings_train[user]:\n",
    "                beta_u[user] += user_item_ratings_train[user][item] - alpha - beta_i[item]\n",
    "            beta_u[user] = beta_u[user]/(lam+len(user_item_ratings_train[user]))\n",
    "\n",
    "        for item in beta_i:\n",
    "            beta_i[item] = 0\n",
    "            for user in item_user_ratings_train[item]:\n",
    "                beta_i[item] += item_user_ratings_train[item][user] - alpha - beta_u[user]\n",
    "            beta_i[item] = beta_i[item]/(lam + len(item_user_ratings_train[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2495251818321746, 'I635442408')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=-400\n",
    "u=''\n",
    "for k in beta_i:\n",
    "    if m < beta_i[k]:\n",
    "        m = beta_i[k]\n",
    "        u = k\n",
    "m,u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in range(len(ratings_train)):\n",
    "    errors.append(abs(ratings_train[i] - alpha - beta_u[users_train[i]] - beta_i[items_train[i]])**2)\n",
    "sum(errors)/len(errors)\n",
    "\n",
    "errors = []\n",
    "for i in range(len(ratings_test)):\n",
    "    errors.append(abs(ratings_test[i] - alpha - beta_u[users_test[i]] - beta_i[items_test[i]])**2)\n",
    "sum(errors)/len(errors)\n",
    "#MSE for training Set = 0.3335585596679398\n",
    "#MSE for test Set = 0.9042631835049043\n",
    "#alpha 4.2003778800008265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042631835049043"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(errors)/len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.838915319212\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for i in range(len(ratings_test)):\n",
    "    errors.append(abs(ratings_test[i] - alpha - beta_u[users_test[i]] - beta_i[items_test[i]])**2)\n",
    "print sum(errors)/len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.21824"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "lam = 1\n",
    "def find_lam(lam):\n",
    "    mse_converge(lam)\n",
    "    return valid_mse()\n",
    "x = scipy.optimize.minimize(find_lam,[1],args=(),method=\"BFGS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_predict(i,u):\n",
    "    return (alpha + beta_u[u] + beta_i[i] )\n",
    "\n",
    "predictions = open(\"predictions_Ratings.txt\", 'w')\n",
    "\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    pred = model_predict(i,u)\n",
    "    predictions.write(u + '-' + i + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()\n",
    "\n",
    "#0.838915319212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2003778800008265"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in range(len(ratings_test)):\n",
    "    errors.append((ratings_test[i] - alpha - beta_u[users_test[i]] - beta_i[items_test[i]])**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042631835049043"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(errors)/len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THis is s acengesl', ' aldkf', '']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"THis is s acengesl. aldkf.\".split('.')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('say \"Hello\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = 'This book \"succubi\" me in from the first paragraph. Jackie Brigton wakes up in a dumpster to find some where she lost a whole day. What more she on the opposite side of town from where she lives and with an actual Angel interested in her. Seems the combination of a night spent with both an angel and a vampire has turned her into a sex demon known as a succubi. Angel Noah introduce Jackie to Remy a porn star Succubi who happy to have one of her own in town. Unfortunately her world has only started to turn upside down as she now has two masters who have complete over her (an angel and a vampire.)  Jackie and her new immortal friends find themselves in the middle of an angel/vampire feud of power. Both sides wanting a halo which if either side hand would end the world as Jackie knows it. In order so save Noah\\'s life Jackie find herself in a no win situation with the world itself at stake.'\n",
    "a = [len(i.split()) for i in a.split('. ')]\n",
    "a = sum(a)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
